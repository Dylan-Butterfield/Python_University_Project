{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b355b265-6b97-4a48-be8c-cdf3cda9d979",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell to delete\n",
    "\n",
    "df = pd.read_csv('Occupancy_Estimation.csv')  #,nrows = 100\n",
    "\n",
    "#print(len(df))\n",
    "\n",
    "#10126, 10127, 10128\n",
    "\n",
    "#print(df.iloc[10127:10129,0])\n",
    "\n",
    "df_duplicate_handling = row_duplication(df.copy())\n",
    "\n",
    "#print(len(df_duplicate_handling))\n",
    "\n",
    "#print(df_duplicate_handling.duplicated())\n",
    "\n",
    "#print(df_duplicate_handling.drop_duplicates())\n",
    "\n",
    "#import pandas as pd\n",
    "#import numpy as np\n",
    "\n",
    "#df_cleaning_example = load_olympus_data(\"https://olympus.ntu.ac.uk/N1423084/SOFT40161_Intro-to-Computer-Programming/blob/main/Assessment/Occupancy_Estimation.csv\")\n",
    "\n",
    "#df = pd.read_csv('Occupancy_Estimation.csv', nrows = 100)\n",
    "\n",
    "#df_cleaning_example = pd.read_csv('Occupancy_Estimation.csv', nrows = 100)\n",
    "#df_cleaning_example.iloc[20:35,:] = np.nan\n",
    "\n",
    "#print(df_cleaning_example.iloc[20:24,:])\n",
    "\n",
    "#null_checker(df)\n",
    "\n",
    "#null_handling(df)\n",
    "\n",
    "#x = null_checker(df_cleaning_example)\n",
    "\n",
    "#y = null_handling(df_cleaning_example)\n",
    "\n",
    "#print(y)\n",
    "\n",
    "#print()\n",
    "\n",
    "#z = null_checker(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d016655-609c-4acb-9ad8-5323fe7b82d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function Creation to Delete\n",
    "\n",
    "#import pandas as pd\n",
    "#import numpy as np\n",
    "\n",
    "df = pd.read_csv('Occupancy_Estimation.csv', nrows = 100)\n",
    "\n",
    "#print(df)\n",
    "\n",
    "#range_input1 = input(\"Pick a starting row\") \n",
    "#range_input2 = input(\"Pick the n+1 to your chosen end row\")\n",
    "\n",
    "test_list = []\n",
    "\n",
    "print(df.iloc[0,:])\n",
    "\n",
    "#for x in range(int(range_input1), int(range_input2)):\n",
    "for x in range(0,2):\n",
    "    df2 = df.iloc[x,:]\n",
    "    test_list.append(df2)\n",
    "\n",
    "df3 = pd.DataFrame(test_list)\n",
    "\n",
    "df4 = pd.concat([df,df3], ignore_index = True)\n",
    "\n",
    "df4.duplicated()\n",
    "\n",
    "#df2 = df.iloc[[0,10]]\n",
    "\n",
    "#df3\n",
    "\n",
    "#df3 = pd.concat([df,df2], ignore_index = True)\n",
    "\n",
    "#print(df3.tail(1), df3.head(1))\n",
    "\n",
    "#df3.duplicated()\n",
    "\n",
    "#column_headings = df.columns.tolist()\n",
    "#null = df.isnull()\n",
    "\n",
    "#df_cleaning_example = pd.read_csv('Occupancy_Estimation.csv', nrows = 100)\n",
    "#column_headings = df_cleaning_example.columns.tolist()\n",
    "\n",
    "#d_types = df.dtypes\n",
    "\n",
    "#d_types = df_cleaning_example.dtypes\n",
    "\n",
    "#original = null_checker(df)\n",
    "\n",
    "#df_cleaning_example.iloc[np.r_[20:25,50:55],:] = np.nan\n",
    "\n",
    "#print(df_cleaning_example.iloc[np.r_[20:25,50:55],:])\n",
    "\n",
    "#null_cleaning_example = df_cleaning_example.isnull()\n",
    "\n",
    "#Total_nulls_per_column = null_cleaning_example.sum()\n",
    "\n",
    "#print(Total_nulls_per_column)\n",
    "\n",
    "#Percentage_Null_List = []\n",
    "\n",
    "#for heading in column_headings:\n",
    "#    Percentage_Null = Total_nulls_per_column[heading]/len(df_cleaning_example[heading]) \n",
    "    #print(Percentage_Null_Date)\n",
    "#    Percentage_Null_List.append(Percentage_Null)\n",
    "#Percentage_Null_df = pd.DataFrame.from_dict([Percentage_Null_Dic], orient = 'columns')\n",
    "\n",
    "#print(max(Percentage_Null_List))\n",
    "\n",
    "#print(Percentage_Null_df)\n",
    "\n",
    "#print(df_cleaning_example.iloc[20:25,:])\n",
    "\n",
    "#print(Percentage_Null_df['Time'].values[0])\n",
    "    \n",
    "#print(d_types)\n",
    "\n",
    "#if max(Percentage_Null_List) <= 0.05:\n",
    "#    df_cleaning_example = df_cleaning_example.dropna()\n",
    "#else:\n",
    "#    for heading in column_headings: \n",
    "#        if d_types[heading] == object:\n",
    "#            df_cleaning_example[heading] = df_cleaning_example[heading].fillna(\"Data Needs Filling\")\n",
    "#        elif d_types[heading] == float or d_types[heading] == int:\n",
    "#            df_cleaning_example[heading] = df_cleaning_example[heading].fillna(df[heading].median())\n",
    "\n",
    "\n",
    "#new = null_checker(df)\n",
    "\n",
    "#print(df_cleaning_example)\n",
    "\n",
    "#print(df_cleaning_example.iloc[20:25,:])\n",
    "\n",
    "#print()\n",
    "\n",
    "#print(df.iloc[20:25,:])\n",
    "\n",
    "#print(df)\n",
    "#print(original)\n",
    "#print()\n",
    "#print(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9004b8ae-e772-477b-9b32-81daf988c56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Max Value Function Creation\n",
    "\n",
    "column_headings = df.columns.tolist()\n",
    "\n",
    "new_column_headings = column_headings[2:15]\n",
    "\n",
    "#print(new_column_headings)\n",
    "\n",
    "df_date = df[\"Date\"]\n",
    "\n",
    "dates = df_date.unique()\n",
    "\n",
    "#print(dates)\n",
    "\n",
    "#dates[0]\n",
    "\n",
    "#print(len(dates))\n",
    "\n",
    "date_dic_max_values = {}\n",
    "\n",
    "for i in range(len(dates)): \n",
    "    date_dic = {}\n",
    "    for headings in new_column_headings:\n",
    "        filter_date = df.loc[df[\"Date\"] == dates[i] , [headings]]\n",
    "        max_value = filter_date[headings].max()\n",
    "        #print(max_value)\n",
    "        date_dic[headings] = max_value\n",
    "    date_dic_max_values[dates[i]] = date_dic.copy()\n",
    "\n",
    "#print(date_dic_max_values)\n",
    "\n",
    "#Max_df = pd.DataFrame(date_dic_max_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4534f095-3109-4b58-922d-481c0711345e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking Raw Dataset For Missing Values\n",
    "\n",
    "null_checker(df)\n",
    "\n",
    "#Examples to show null handling of missing data\n",
    "\n",
    "# Removal of null rows when the number of missing data is too few.\n",
    "\n",
    "df_cleaning_example1 = df.copy()\n",
    "\n",
    "df_cleaning_example1.iloc[180:200,:] = np.nan\n",
    "null_checker(df_cleaning_example1)\n",
    "ex1 = null_handling(df_cleaning_example1)\n",
    "null_checker(ex1)\n",
    "\n",
    "print()\n",
    "\n",
    "# Handling null data row when a large amount of data is missing\n",
    "\n",
    "df_cleaning_example2 = df.copy()\n",
    "df_cleaning_example2.iloc[np.r_[800:1000,6425:6725],:] = np.nan\n",
    "null_checker(df_cleaning_example2)\n",
    "ex2 = null_handling(df_cleaning_example2)\n",
    "null_checker(ex2)\n",
    "\n",
    "#Handling duplicates\n",
    "\n",
    "#Showing Dataset has no duplicates\n",
    "\n",
    "print(df.duplicated().value_counts())\n",
    "\n",
    "#Example to show handling of duplicated rows\n",
    "\n",
    "df_duplicate_example = df.copy()\n",
    "\n",
    "df_duplicate_handling = row_duplication(df_duplicate_example)\n",
    "\n",
    "print(df_duplicate_handling.duplicated().value_counts())\n",
    "\n",
    "print(len(df_duplicate_handling.drop_duplicates()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27877f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Creating DataFrame\n",
    "#df = load_olympus_data(\"https://olympus.ntu.ac.uk/N1423084/SOFT40161_Intro-to-Computer-Programming/blob/main/Assessment/Occupancy_Estimation.csv\")\n",
    "df = pd.read_csv('Occupancy_Estimation.csv')\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "#Filtering Max Data\n",
    "\n",
    "df_date = df[\"Date\"]\n",
    "dates = df_date.unique()\n",
    "\n",
    "filter_column_headings = [\"Date\", \"Time\", \"S6_PIR\", \"S7_PIR\", \"Room_Occupancy_Count\"]\n",
    "\n",
    "filter_date_22_12_17 = df[(df[\"Date\"] == \"22/12/2017\" ) & ((df[\"S1_Temp\"] == Max_df.iloc[0,0]) | (df[\"S2_Temp\"] == Max_df.iloc[1,0]) | (df[\"S3_Temp\"] == Max_df.iloc[2,0]) | (df[\"S4_Temp\"] == Max_df.iloc[3,0]) | (df[\"S1_Light\"] == Max_df.iloc[4,0])| (df[\"S2_Light\"] == Max_df.iloc[5,0]) | (df[\"S3_Light\"] == Max_df.iloc[6,0])| (df[\"S4_Light\"] == Max_df.iloc[7,0]) | (df[\"S1_Sound\"] == Max_df.iloc[8,0])| (df[\"S2_Sound\"] == Max_df.iloc[9,0]) | (df[\"S3_Sound\"] == Max_df.iloc[10,0]) | (df[\"S4_Sound\"] == Max_df.iloc [11,0]) |(df[\"S5_CO2\"] == Max_df.iloc[12,0]))]\n",
    "    \n",
    "filter_date_23_12_17 = df[(df[\"Date\"] == \"23/12/2017\" ) & ((df[\"S1_Temp\"] == Max_df.iloc[0,1]) | (df[\"S2_Temp\"] == Max_df.iloc[1,1]) | (df[\"S3_Temp\"] == Max_df.iloc[2,1]) | (df[\"S4_Temp\"] == Max_df.iloc[3,1]) | (df[\"S1_Light\"] == Max_df.iloc[4,1])| (df[\"S2_Light\"] == Max_df.iloc[5,1]) | (df[\"S3_Light\"] == Max_df.iloc[6,1])| (df[\"S4_Light\"] == Max_df.iloc[7,1]) | (df[\"S1_Sound\"] == Max_df.iloc[8,1])| (df[\"S2_Sound\"] == Max_df.iloc[9,1]) | (df[\"S3_Sound\"] == Max_df.iloc[10,1]) | (df[\"S4_Sound\"] == Max_df.iloc [11,1]) |(df[\"S5_CO2\"] == Max_df.iloc[12,1]))]\n",
    "\n",
    "filter_date_24_12_17 = df[(df[\"Date\"] == \"24/12/2017\" ) & ((df[\"S1_Temp\"] == Max_df.iloc[0,2]) | (df[\"S2_Temp\"] == Max_df.iloc[1,2]) | (df[\"S3_Temp\"] == Max_df.iloc[2,2]) | (df[\"S4_Temp\"] == Max_df.iloc[3,2]) | (df[\"S1_Light\"] == Max_df.iloc[4,2])| (df[\"S2_Light\"] == Max_df.iloc[5,2]) | (df[\"S3_Light\"] == Max_df.iloc[6,2])| (df[\"S4_Light\"] == Max_df.iloc[7,2]) | (df[\"S1_Sound\"] == Max_df.iloc[8,2])| (df[\"S2_Sound\"] == Max_df.iloc[9,2]) | (df[\"S3_Sound\"] == Max_df.iloc[10,2]) | (df[\"S4_Sound\"] == Max_df.iloc [11,2]) |(df[\"S5_CO2\"] == Max_df.iloc[12,2]))]\n",
    "\n",
    "filter_date_25_12_17 = df[(df[\"Date\"] == \"25/12/2017\" ) & ((df[\"S1_Temp\"] == Max_df.iloc[0,3]) | (df[\"S2_Temp\"] == Max_df.iloc[1,3]) | (df[\"S3_Temp\"] == Max_df.iloc[2,3]) | (df[\"S4_Temp\"] == Max_df.iloc[3,3]) | (df[\"S1_Light\"] == Max_df.iloc[4,3])| (df[\"S2_Light\"] == Max_df.iloc[5,3]) | (df[\"S3_Light\"] == Max_df.iloc[6,3])| (df[\"S4_Light\"] == Max_df.iloc[7,3]) | (df[\"S1_Sound\"] == Max_df.iloc[8,3])| (df[\"S2_Sound\"] == Max_df.iloc[9,3]) | (df[\"S3_Sound\"] == Max_df.iloc[10,3]) | (df[\"S4_Sound\"] == Max_df.iloc [11,3]) |(df[\"S5_CO2\"] == Max_df.iloc[12,3]))]\n",
    "\n",
    "filter_date_26_12_17 = df[(df[\"Date\"] == \"26/12/2017\" ) & ((df[\"S1_Temp\"] == Max_df.iloc[0,4]) | (df[\"S2_Temp\"] == Max_df.iloc[1,4]) | (df[\"S3_Temp\"] == Max_df.iloc[2,4]) | (df[\"S4_Temp\"] == Max_df.iloc[3,4]) | (df[\"S1_Light\"] == Max_df.iloc[4,4])| (df[\"S2_Light\"] == Max_df.iloc[5,4]) | (df[\"S3_Light\"] == Max_df.iloc[6,4])| (df[\"S4_Light\"] == Max_df.iloc[7,4]) | (df[\"S1_Sound\"] == Max_df.iloc[8,4])| (df[\"S2_Sound\"] == Max_df.iloc[9,4]) | (df[\"S3_Sound\"] == Max_df.iloc[10,4]) | (df[\"S4_Sound\"] == Max_df.iloc [11,4]) |(df[\"S5_CO2\"] == Max_df.iloc[12,4]))]\n",
    "\n",
    "filter_date_10_01_18 = df[(df[\"Date\"] == \"10/01/2018\" ) & ((df[\"S1_Temp\"] == Max_df.iloc[0,5]) | (df[\"S2_Temp\"] == Max_df.iloc[1,5]) | (df[\"S3_Temp\"] == Max_df.iloc[2,5]) | (df[\"S4_Temp\"] == Max_df.iloc[3,5]) | (df[\"S1_Light\"] == Max_df.iloc[4,5])| (df[\"S2_Light\"] == Max_df.iloc[5,5]) | (df[\"S3_Light\"] == Max_df.iloc[6,5])| (df[\"S4_Light\"] == Max_df.iloc[7,5]) | (df[\"S1_Sound\"] == Max_df.iloc[8,5])| (df[\"S2_Sound\"] == Max_df.iloc[9,5]) | (df[\"S3_Sound\"] == Max_df.iloc[10,5]) | (df[\"S4_Sound\"] == Max_df.iloc [11,5]) |(df[\"S5_CO2\"] == Max_df.iloc[12,5]))]\n",
    "\n",
    "filter_date_11_01_18 = df[(df[\"Date\"] == \"11/01/2018\" ) & ((df[\"S1_Temp\"] == Max_df.iloc[0,6]) | (df[\"S2_Temp\"] == Max_df.iloc[1,6]) | (df[\"S3_Temp\"] == Max_df.iloc[2,6]) | (df[\"S4_Temp\"] == Max_df.iloc[3,6]) | (df[\"S1_Light\"] == Max_df.iloc[4,6])| (df[\"S2_Light\"] == Max_df.iloc[5,6]) | (df[\"S3_Light\"] == Max_df.iloc[6,6])| (df[\"S4_Light\"] == Max_df.iloc[7,6]) | (df[\"S1_Sound\"] == Max_df.iloc[8,6])| (df[\"S2_Sound\"] == Max_df.iloc[9,6]) | (df[\"S3_Sound\"] == Max_df.iloc[10,6]) | (df[\"S4_Sound\"] == Max_df.iloc [11,6]) |(df[\"S5_CO2\"] == Max_df.iloc[12,6]))]\n",
    "\n",
    "filter_date_10_01_18.loc[:,filter_column_headings]\n",
    "\n",
    "#filter_max_CO2 = filter_data[filter_data[\"S5_CO2\"] == Max_df.iloc[12,0]]\n",
    "\n",
    "#filter_data.iloc[:,14]\n",
    "\n",
    "#filter_max_CO2\n",
    "\n",
    "#column_headings = df.columns.tolist()\n",
    "#new_column_headings = column_headings[2:15]\n",
    "\n",
    "#len(dates)\n",
    "\n",
    "#for j in range(1):\n",
    "    #for n , index in enumerate(len(Max_df)):\n",
    "#        filter_data = df[(df[\"Date\"] == dates[j]) & (df[new_column_headings[n]] == Max_df.iloc[index,0])]\n",
    "#        print(filter_data)\n",
    "\n",
    "\n",
    "#print(list(enumerate(new_column_headings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bea10ce1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#filter_data = df[(df[\"Date\"] == \"22/12/2017\") & (df[\"S4_Sound\"] == Max_df.iloc[11,0])]\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m pd\u001b[38;5;241m.\u001b[39mset_option(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisplay.max_rows\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m120\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#print(len(new_column_headings))\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#print(len(dates))\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m \n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#| (df[\"S2_Temp\"] == Max_df.iloc[1,0]) | (df[\"S3_Temp\"] == Max_df.iloc[2,0]) | (df[\"S4_Light\"] == Max_df.iloc[7,0]) | (df[\"S5_CO2\"] == Max_df.iloc[12,0]\u001b[39;00m\n\u001b[0;32m     11\u001b[0m filter_date_22_12_17\u001b[38;5;241m.\u001b[39mloc[:,filter_column_headings]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "#filter_data = df[(df[\"Date\"] == \"22/12/2017\") & (df[\"S4_Sound\"] == Max_df.iloc[11,0])]\n",
    "pd.set_option('display.max_rows', 120)\n",
    "#print(len(new_column_headings))\n",
    "\n",
    "#print(len(dates))\n",
    "\n",
    "#print(len(Max_df))\n",
    "\n",
    "#| (df[\"S2_Temp\"] == Max_df.iloc[1,0]) | (df[\"S3_Temp\"] == Max_df.iloc[2,0]) | (df[\"S4_Light\"] == Max_df.iloc[7,0]) | (df[\"S5_CO2\"] == Max_df.iloc[12,0]\n",
    "\n",
    "filter_date_22_12_17.loc[:,filter_column_headings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c304d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('Occupancy_Estimation.csv')\n",
    "\n",
    "headings = [\"Date\",\"Time\", \"S1_Temp\", \"S2_Temp\", \"S3_Temp\",\t\"S4_Temp\",\t\"S1_Light\",\t\"S2_Light\",\t\"S3_Light\",\t\"S4_Light\",\t\"S1_Sound\",\t\n",
    "\"S2_Sound\",\t\"S3_Sound\",\t\"S4_Sound\",\t\"S5_CO2\",\t\"S5_CO2_Slope\",\t\"S6_PIR\",\t\"S7_PIR\",\t\"Room_Occupancy_Count\"]\n",
    "\n",
    "#print(df.columns.tolist())\n",
    "\n",
    "info = df.describe()\n",
    "head = df.head(10)\n",
    "null = df.isnull()\n",
    "\n",
    "for heading in headings:\n",
    "    null_count = null.value_counts(heading)\n",
    "    #null_list = null_count.append()\n",
    "    #print(null_count)\n",
    "    #print()\n",
    "\n",
    "#print(null_count)\n",
    "\n",
    "#print(info)\n",
    "#print(head)\n",
    "#print(null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4b917a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('Occupancy_Estimation.csv')\n",
    "\n",
    "column_headings = df.columns.tolist()\n",
    "\n",
    "new_column_headings = column_headings[2:15]\n",
    "\n",
    "#print(new_column_headings)\n",
    "\n",
    "df_date = df[\"Date\"]\n",
    "\n",
    "dates = df_date.unique()\n",
    "\n",
    "#dates[0]\n",
    "\n",
    "#len(dates)\n",
    "\n",
    "max_sensor = []\n",
    "date_dic = {}\n",
    "date_dic2 = {}\n",
    "\n",
    "filter_date = df.loc[df[\"Date\"] == dates[0] , [\"S1_Temp\"]]\n",
    "\n",
    "max_value = filter_date[\"S1_Temp\"].max()\n",
    "\n",
    "date_dic[\"S1_Temp\"] = max_value\n",
    "\n",
    "filter_date1 = df.loc[df[\"Date\"] == dates[0] , [\"S2_Temp\"]]\n",
    "\n",
    "max_value1 = filter_date1[\"S2_Temp\"].max()\n",
    "\n",
    "date_dic[\"S2_Temp\"] = max_value1\n",
    "\n",
    "date_dic2[dates[0]] = date_dic\n",
    "\n",
    "date_dic3 = {}\n",
    "\n",
    "filter_date3 = df.loc[df[\"Date\"] == dates[1] , [\"S1_Temp\"]]\n",
    "\n",
    "max_value3 = filter_date3[\"S1_Temp\"].max()\n",
    "\n",
    "date_dic3[\"S1_Temp\"] = max_value3\n",
    "\n",
    "date_dic2[dates[1]] = date_dic3\n",
    "\n",
    "print(date_dic2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b35bfe-e289-4f86-8093-8a00ec113345",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pairplot1 = df.loc[df[\"Date\"] == \"23/12/2017\", [\"S1_Temp\", \"S2_Temp\", \"S3_Temp\", \"S4_Temp\", \"S5_CO2\"]] \n",
    "\n",
    "df_pairplot2 = df.loc[df[\"Date\"] == \"24/12/2017\", [\"S1_Temp\", \"S2_Temp\", \"S3_Temp\", \"S4_Temp\"]] \n",
    "\n",
    "df_pairplot3 = df.loc[df[\"Date\"] == \"25/12/2017\", [\"S1_Temp\", \"S2_Temp\", \"S3_Temp\", \"S4_Temp\"]] \n",
    "\n",
    "df_pairplot4 = df.loc[df[\"Date\"] == \"26/12/2017\", [\"S1_Temp\", \"S2_Temp\", \"S3_Temp\", \"S4_Temp\"]] \n",
    "\n",
    "df_pairplot5 = df.loc[df[\"Date\"] == \"10/01/2018\", [\"S1_Temp\", \"S2_Temp\", \"S3_Temp\", \"S4_Temp\"]] \n",
    "\n",
    "df_pairplot6 = df.loc[df[\"Date\"] == \"11/01/2018\", [\"S1_Temp\", \"S2_Temp\", \"S3_Temp\", \"S4_Temp\"]] \n",
    "\n",
    "df_pairplot7 = df.loc[df[\"Date\"] == \"22/12/2017\", [\"S1_Temp\", \"S2_Temp\", \"S3_Temp\", \"S4_Temp\"]] \n",
    "\n",
    "df_pairplot8 = df.loc[df[\"Date\"] == \"23/12/2017\", [\"S2_Temp\", \"S2_Light\", \"S2_Sound\", \"S5_CO2\",\"Room_Occupancy_Count\"]] \n",
    "\n",
    "df_pairplot9 = df.loc[:, [\"Date\",\"S1_Temp\", \"S2_Temp\", \"S3_Temp\", \"S4_Temp\", \"S5_CO2\"]] \n",
    "\n",
    "df_pairplot10 = df.loc[:, [\"Date\",\"S1_Light\", \"S2_Light\", \"S3_Light\", \"S4_Light\"]] \n",
    "\n",
    "df_pairplot11 = df.loc[df[\"Date\"] == \"23/12/2017\", [\"S1_Light\", \"S2_Light\", \"S3_Light\", \"S4_Light\"]] \n",
    "\n",
    "df_pairplot12 = df.loc[df[\"Date\"] == \"23/12/2017\", [\"S1_Sound\", \"S2_Sound\", \"S3_Sound\", \"S4_Sound\"]] \n",
    "\n",
    "df_pairplot13 = df.loc[df[\"Room_Occupancy_Count\"] > 0, [\"Date\",\"S1_Sound\", \"S2_Sound\", \"S3_Sound\", \"S4_Sound\"]] \n",
    "\n",
    "df_pairplot14 = df.loc[df[\"Room_Occupancy_Count\"] > 0, [\"Date\",\"S1_Light\", \"S2_Light\", \"S3_Light\", \"S4_Light\"]] \n",
    "\n",
    "df_pairplot15 = df.loc[df[\"Room_Occupancy_Count\"] > 0, [\"Date\",\"S1_Temp\", \"S2_Temp\", \"S3_Temp\", \"S4_Temp\"]] \n",
    "\n",
    "df_pairplot16 = df.loc[:, [\"Date\",\"S1_Temp\", \"S1_Light\", \"S1_Sound\", \"S5_CO2\"]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856c200c-24cb-4c55-b80f-fb82073ff4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df_heatmap = df.copy() \n",
    "\n",
    "heat_map_dates = [\"22/12/2017\", \"23/12/2017\", \"25/12/2017\"]\n",
    "\n",
    "df_heatmap[\"Time\"] = pd.to_datetime(df_heatmap[\"Time\"], format = \"%H:%M:%S\")\n",
    "df_heatmap[\"Time\"] = df_heatmap[\"Time\"].dt.strftime(\"%H:%M\")\n",
    "\n",
    "df_filtered = df_heatmap.loc[:, [\"Date\", \"Time\", \"S5_CO2\"]]\n",
    "\n",
    "heatmap_group = df_filtered.groupby([\"Date\",\"Time\"], as_index = False).mean()\n",
    "\n",
    "heatmap_reduction = heatmap_group[(heatmap_group[\"Date\"].isin(heat_map_dates)) & (heatmap_group[\"Time\"] >= \"11:00\") & (heatmap_group[\"Time\"] <= \"23:00\")] \n",
    "\n",
    "heatmap_missing_time = {\n",
    "                        \"Date\": [\"23/12/2017\", \"23/12/2017\"],\n",
    "                        \"Time\": [\"16:38\", \"16:39\"],\n",
    "                        \"S5_CO2\": [535, 535]\n",
    "}\n",
    "\n",
    "missing_time_df = pd.DataFrame(heatmap_missing_time)\n",
    "\n",
    "equal_time_spacing = heatmap_reduction.loc[heatmap_reduction[\"Date\"] == \"22/12/2017\", [\"Time\"]]\n",
    "\n",
    "equal_time_spacing_list = equal_time_spacing[\"Time\"].tolist()\n",
    "\n",
    "heatmap_equalising_time_entries = heatmap_reduction[(heatmap_reduction[\"Time\"].isin(equal_time_spacing_list))]\n",
    "\n",
    "heatmap_equalising_time_entries2 = pd.concat([heatmap_equalising_time_entries, missing_time_df]) \n",
    "\n",
    "heatmap_date = heatmap_reduction[\"Date\"].unique().tolist()\n",
    "\n",
    "heatmap_time = heatmap_reduction[\"Time\"].tolist()\n",
    "\n",
    "#heatmap_equalising_time_entries2.to_csv(\"Check4.csv\")\n",
    "\n",
    "Final_dic = {}\n",
    "\n",
    "#date_filter = heatmap_reduction.loc[heatmap_reduction[\"Date\"] == \"22/12/2017\",\"S5_CO2\"]\n",
    "\n",
    "for dates in heatmap_date:\n",
    "    for time in equal_time_spacing_list:\n",
    "        date_filter = heatmap_equalising_time_entries2.loc[heatmap_equalising_time_entries2[\"Date\"] == dates,\"S5_CO2\"]\n",
    "        CO2_List = date_filter.tolist()\n",
    "        Final_dic[dates] = CO2_List\n",
    "\n",
    "heatmap_df = pd.DataFrame(Final_dic, index = equal_time_spacing_list)\n",
    "\n",
    "#heatmap_df.to_csv(\"Check5.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
